{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, feature_extraction, preprocessing, svm, pipeline, metrics\n",
    "from project_utilities import import_train_data, import_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(import_train_data())\n",
    "test_data = pd.DataFrame(import_test_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good to use 80% and 20% of the dataset for training and testing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = model_selection.train_test_split(\n",
    "    train_data.drop(columns=['category']), \n",
    "    train_data.drop(columns=['text']), \n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline structures the raw data. It also extracts and selects features from the structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF-IDF and Linear SVM with GridSearch Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pipeline = pipeline.Pipeline([\n",
    "    ('vect', feature_extraction.text.CountVectorizer()),\n",
    "    ('tfidf', feature_extraction.text.TfidfTransformer()),\n",
    "    ('norm', preprocessing.Normalizer()),\n",
    "    ('clf', svm.LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=6)]: Done  16 out of  24 | elapsed:  1.2min remaining:   35.3s\n",
      "[Parallel(n_jobs=6)]: Done  19 out of  24 | elapsed:  1.5min remaining:   23.7s\n",
      "[Parallel(n_jobs=6)]: Done  22 out of  24 | elapsed:  1.7min remaining:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done  24 out of  24 | elapsed:  1.8min finished\n",
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=6,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2), (2, 2)], 'tfidf__use_idf': [True, False], 'clf__C': [1, 10], 'clf__random_state': [551]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 551\n",
    "parameters = {'vect__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "             'tfidf__use_idf': [True, False],\n",
    "             'clf__C': [1, 10],\n",
    "             'clf__random_state': [551]}\n",
    "\n",
    "grid_search_cv = model_selection.GridSearchCV(classifier_pipeline, parameters, cv=2, n_jobs=6, verbose=10)\n",
    "grid_search_cv.fit(X_train['text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf__C': 10, 'clf__random_state': 551, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', grid_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      2507\n",
      "           1       0.89      0.91      0.90      2493\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      5000\n",
      "   macro avg       0.90      0.90      0.90      5000\n",
      "weighted avg       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_search_cv.predict(X_validation['text'])\n",
    "\n",
    "print(metrics.classification.classification_report(y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_set = grid_search_cv.predict(test_data['text'])\n",
    "\n",
    "d = {'Id' : test_data['id'], 'Category': predictions_test_set}\n",
    "submission = pd.DataFrame(data=d).sort_values(by=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
