{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, feature_extraction, preprocessing, svm, pipeline, metrics, tree, linear_model\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.json') as fd:\n",
    "    train_data = pd.DataFrame(json.load(fd))\n",
    "    \n",
    "with open('test_data.json') as fd:\n",
    "    test_data = pd.DataFrame(json.load(fd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good to use 80% and 20% of the dataset for training and testing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = model_selection.train_test_split(\n",
    "    train_data.drop(columns=['category']), \n",
    "    train_data.drop(columns=['text']), \n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following experiments are already using pipelining. The pipeline structures the raw data. It also extracts and selects features from the structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf_pipeline_logistic_reg = pipeline.Pipeline([\n",
    "    ('vect', feature_extraction.text.CountVectorizer()),\n",
    "    ('norm', preprocessing.Normalizer()),\n",
    "    ('clf', linear_model.LogisticRegression())])\n",
    "\n",
    "clf_pipeline_logistic_reg.fit(X_train['text'], y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      2492\n",
      "           1       0.85      0.86      0.86      2508\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_reg_predictions = clf_pipeline_logistic_reg.predict(X_validation['text'])\n",
    "\n",
    "print(metrics.classification_report(y_validation, logistic_reg_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline_tree = pipeline.Pipeline([\n",
    "    ('vect', feature_extraction.text.CountVectorizer()),\n",
    "    ('norm', preprocessing.Normalizer()),\n",
    "    ('clf', tree.DecisionTreeClassifier())])\n",
    "\n",
    "clf_pipeline_tree.fit(X_train['text'], y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      2492\n",
      "           1       0.71      0.72      0.71      2508\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      5000\n",
      "   macro avg       0.71      0.71      0.71      5000\n",
      "weighted avg       0.71      0.71      0.71      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_predictions = clf_pipeline_tree.predict(X_validation['text'])\n",
    "\n",
    "print(metrics.classification_report(y_validation, tree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf_pipeline_svm = pipeline.Pipeline([\n",
    "    ('vect', feature_extraction.text.CountVectorizer()),\n",
    "    ('norm', preprocessing.Normalizer()),\n",
    "    ('clf', svm.LinearSVC())])\n",
    "\n",
    "clf_pipeline_svm.fit(X_train['text'], y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      2492\n",
      "           1       0.88      0.89      0.89      2508\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = clf_pipeline_svm.predict(X_validation['text'])\n",
    "\n",
    "print(metrics.classification_report(y_validation, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Different Feature Extraction Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline_svm_bin = pipeline.Pipeline([\n",
    "    ('vect', feature_extraction.text.HashingVectorizer(binary=True)),\n",
    "    ('norm', preprocessing.Normalizer()),\n",
    "    ('clf', svm.LinearSVC())])\n",
    "\n",
    "clf_pipeline_svm_bin.fit(X_train['text'], y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      2492\n",
      "           1       0.88      0.89      0.88      2508\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5000\n",
      "   macro avg       0.88      0.88      0.88      5000\n",
      "weighted avg       0.88      0.88      0.88      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_bin_predictions = clf_pipeline_svm_bin.predict(X_validation['text'])\n",
    "\n",
    "print(metrics.classification_report(y_validation, svm_bin_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline_svm_tfidf = pipeline.Pipeline([\n",
    "    ('vect', feature_extraction.text.CountVectorizer()),\n",
    "    ('tfidf', feature_extraction.text.TfidfTransformer()),\n",
    "    ('norm', preprocessing.Normalizer()),\n",
    "    ('clf', svm.LinearSVC())])\n",
    "\n",
    "clf_pipeline_svm_tfidf.fit(X_train['text'], y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      2492\n",
      "           1       0.89      0.90      0.90      2508\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf_predictions = clf_pipeline_svm_tfidf.predict(X_validation['text'])\n",
    "\n",
    "print(metrics.classification_report(y_validation, svm_tfidf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Parameters\n",
    "These parameters will used in GridResearch and RandomResearch to see if they can improve accuracy.<br>\n",
    "\n",
    "textblob_tokenizer, stemming_tokenizer, token.tokenize, and nltk.word_tokenize are the custom paramerters for the tokenizing process in CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Try TextBlob\n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "# Try NLTK's PorterStemmer\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\matth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF-IDF and Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our best classifier so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline_svm = pipeline.Pipeline([\n",
    "    ('vect', feature_extraction.text.CountVectorizer()),\n",
    "    ('tfidf', feature_extraction.text.TfidfTransformer()),\n",
    "    ('norm', preprocessing.Normalizer()),\n",
    "    ('clf', svm.LinearSVC())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of  12 | elapsed:   22.6s remaining:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done   5 out of  12 | elapsed:   25.0s remaining:   35.0s\n",
      "[Parallel(n_jobs=6)]: Done   7 out of  12 | elapsed:   32.7s remaining:   23.3s\n",
      "[Parallel(n_jobs=6)]: Done   9 out of  12 | elapsed:   51.9s remaining:   17.2s\n",
      "[Parallel(n_jobs=6)]: Done  12 out of  12 | elapsed:   56.8s finished\n",
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf__C': 10, 'clf__random_state': 551, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'vect__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "              'vect__max_features':[None],\n",
    "              'vect__binary': [True],\n",
    "              'vect__strip_accents': ['ascii'],\n",
    "              'vect__analyzer':['word'],\n",
    "              'vect__max_df' :[1.0],\n",
    "              'vect__tokenizer':[token.tokenize],\n",
    "              'vect__strip_accents': ['unicode'],\n",
    "              'norm__norm': ['l2'],\n",
    "              'tfidf__norm': ['l1'],\n",
    "              'tfidf__smooth_idf': [False],\n",
    "              'tfidf__use_idf': [True],\n",
    "              'clf__random_state': [42],\n",
    "              'clf__C':[1, 10],\n",
    "              'clf__fit_intercept': [True]}\n",
    "\n",
    "grid_search_cv = model_selection.GridSearchCV(clf_pipeline_svm, parameters, cv=2, n_jobs=6, verbose=10, error_score=0)\n",
    "grid_search_cv.fit(X_train['text'], y_train)\n",
    "\n",
    "print('Best Parameters:', grid_search_cv.best_params_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      2492\n",
      "           1       0.90      0.91      0.91      2508\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      5000\n",
      "   macro avg       0.91      0.91      0.91      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_search_cv.predict(X_validation['text'])\n",
    "\n",
    "print(metrics.classification.classification_report(y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random_search = RandomizedSearchCV(clf_pipeline_svm, param_distributions = parameters, cv=2, verbose = 10, random_state = seed, n_iter = 60)\n",
    "random_search.fit(X_train['text'], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_randcv = random_search.predict(X_validation['text'])\n",
    "print(metrics.classification_report(y_validation, y_pred_randcv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Test Set Using Our Best Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_predictions = grid_search_cv.predict(test_data['text'])\n",
    "\n",
    "data = {'Id' : test_data['id'], 'Category': test_set_predictions}\n",
    "submission = pd.DataFrame(data=data)\n",
    "submission = submission.apply(pd.to_numeric).sort_values(by=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
